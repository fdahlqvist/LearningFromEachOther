\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[left=2.00cm, right=2.00cm, top=2.00cm, bottom=2.00cm]{geometry}
\usepackage{tikz}
\usetikzlibrary{arrows.meta, automata, shapes, arrows, calc, positioning, quotes}
\tikzstyle{dfa} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, text=white, fill=blue!100, text width = 6.5cm]
\tikzstyle{nn} = [rectangle,  rounded corners, minimum width=3cm, minimum height=1cm,text centered, text=white, fill=red!100, text width = 6cm]
\tikzstyle{process} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=0.5cm, text centered, draw=black, fill=gray!30, inner xsep=0pt,outer sep=0pt]
\tikzstyle{comparison} = [diamond, text centered, draw=black, fill=green!50, /pgf/aspect=1.3]
\tikzset{
	FARROW/.style={line width=2pt, arrows={-Latex[angle=40:4mm]}}
}
\tikzstyle{arrow} = [thick,->,>=stealth]
\usepackage{url,hyperref}
\begin{document}
	
	
	\section{Overview}
	This project aims to explore how two well-known machine learning paradigms -- \emph{finite automata} and \emph{neural network} learning -- can help improve and explain each other.
	It is structured around  three complementary axes:
	\begin{enumerate}
		\item Using deep neural networks to improve automaton learning.
		\item Using automata to improve deep neural network learning.
		\item Using automata to improve our understanding of deep neural network mechanisms and behaviours.
	\end{enumerate}
	The first two axes combine into the development of an ecosystem of concrete and practical techniques to assist in one type of learning by applying idea from the other. 
	As we will see, this ecosystem could allow us to create learning systems \emph{combining features of both automaton and deep neural network learning}, for instance machine learning systems guided by formal automata-theoretic constraints who are themselves learned with the help of Neural Networks. 
	
	The last axis has a more fundamental and theoretical ambition: to use automata as a highly structured class of classification problems with which to investigate whether \emph{logical and compositional reasoning} can be (a) identified and (b) understood in various deep neural network architectures.
	
	\section{Improving Automaton Learning with deep neural networks}
	\emph{Finite automata} are perhaps the simplest and best-understood model of computation. A finite automaton represents a simple `computing machine' which runs programs written in a very simple `programming language' called a regular expression. An automaton can thus be seen as a classification algorithm deciding whether a given program belongs to such a language or not: simply feed the program to the automaton and check whether it executes successfully or not. Finite automata and variations thereof and not only theoretically important, they also model a huge variety of systems of practical interest in computer science such as networks, decision processes, etc.
	
	In 1987 Dana Angluin developed the now famous $L^\ast$-algorithm~\cite{angluin1987learning} which showed that it is possible to \emph{learn an unknown automaton} by $(i)$ feeding it programs and observing whether they run successfully or not (these interactions are called membership queries), and $(ii)$ asking for a counter-example program that runs successfully on the algorithm's current representation of the unknown automaton, but not on the actual unknown automaton (these interactions are called equivalence queries).  The Cornell pole of the project has unrivalled expertise in applying and extending this algorithm to an extremely wide variety of contexts, e.g.\ learning nominal automata~\cite{moerman2017learning}, tree-automaton~\cite{heerdt2022categorical}, automata for concurrent processes ~\cite{van2021learning}, automata with side-effects~\cite{van2020learning} and apply it to important concrete applications to e.g.\ network verification~\cite{ferreira2021prognosis}.
	  
	There are two practical obstacles to Angluin's algorithm that we believe deep neural networks could alleviate: (1) counter-example generation and (2) scope and scale.
	
	
		\subsection{Counter-example generation}
		A major practical obstacle in Angluin's algorithm is that of implementing equivalence queries since, by definition, the target automaton is unknown. Counter-examples are typically generated by exhaustive testing, which is highly resource and time-intensive. To solve this problem, we propose that the  QMUL pole develop and train neural networks architectures to generate counter-examples in Angluin's learning algorithm. The following strategies will be investigated
		\begin{itemize}
			\item Use the strings which fail membership queries (and are discarded by Angluin's algorithm) to train a Generative Adversarial Network (GAN) to produce counter-examples
			\item Use the strings which fail membership queries to train a transformer architecture to produce counter-examples (using a the alphabet of the automaton as tokens)
			\item Train a classifier using both positive and negative membership queries in parallel to the $L^\ast$-algorithm and use this classifier as the basis for a generative model (there are several techniques to do this \cite{?}) able to produce counter-examples when required.
		\end{itemize}
		
		
		\subsection{Enlarging the scope of automata learning with NN adaptors}
		Another limitation in applying Angluin's algorithm or variants thereof is that in many contexts one of the following problem happens:
		\begin{itemize}
			\item[(i)] \emph{Scale}: the set of instructions which can be submitted to the unknown automaton -- often known as the System Under Learning or SUL -- is extremely large. As a concrete example, consider the case of an unknown network protocol which we are trying to learn. Instructions are packets and the set of possible packets is extremely and unnecessarily large. It is often possible to learn the protocol using a much smaller set of `abstract packets'.
			\item[(ii)] \emph{Scope}: the SUL is not quite a learnable automaton-like structure, but by abstracting some details away it is possible to understand the automaton part of the system.
		\end{itemize}
		
		In both of these instances, learning the unknown system will require the ability to submit coarse-grained abstract queries to the SUL. For the SUL to understand these queries and reply to the membership query, the abstract query must be `concretised' into a query that the SUL can understand.  As an example, in order to learn a network protocol we might not need to specify an exact destination for a packet, but only if it is within our outside the organisation. Thus we want to provide the SUL with abstract packets where the destination field is boolean. For the system to process such a packet it must be concretised and the destination field must be populated by some acceptable value.
		
		DEFINE ADAPTER
		
		Concretising abstract instructions amounts to \emph{generating} concrete instructions from abstract ones. The abstraction function is usually known and thus the task is to design a generative model of the inverse of this function. The application of the concretisation function is often context-dependent, that is to say dependent on previous concretisations, which greatly complicates the problem. This task is currently solved by hand in an ad-hoc way (see e.g.\ \cite{ferreira2021prognosis}), but it is exactly the kind of task that machine-learning algorithms such as next token prediction or sequence-to-sequence translation (Seq2Seq) with transformer architectures are very good at. 
		
		
		We aim to develop a methodology for ...
		
		
	\section{Improving Neural Network Learning with Automata}
		\subsection{Automata-based cost functions}
			The idea of using automata to build cost functions has been explored in \cite{icarte2022reward} in the context of reinforcement learning. In this context, a (coarse-grained! connection with adaptors!) policy is described as a finite automaton together with a reward function for every transition.  
			We believe this idea could be generalised in two directions in the context of this project.
			\begin{enumerate}
				\item First, in terms of applicability. We propose investigating how the idea of constructing a cost/utility function out of a formal specification described by automata-like structures can be used in the context of LLM for code generation. Regular expressions, and variants thereof, are the ideal testing groud for testing this idea as they form what is arguably the simplest non-trivial example of formal/programming language. The idea would be to investigate if objective functions which penalise incorrect syntax encoded as automaton can be used to in the training of LLMs designed to generate regexes.
				\item Second, in terms of mathematics. Automata-based cost functions, reward-machines in the terminology of \cite{icarte2022reward}, are very ad-hoc constructions. Are there general constructions which can turn an automaton, of generalisation thereof, into an objective function? Ideally such a function would come with certain guarantees, for example being convex. Is this possible? And how can these function be combined to reflect the various ways in which automata can be combined? In other words, is there a compositional approach to `reward machines'?
			\end{enumerate} 
		
		\subsection{Towards Large \emph{Formal} Language Models (LFLMs): the case of regular expressions}
			Beyond the idea of automata-based cost functions. We plan to investigate the possibility of enforcing correct syntax into LLM by researching ways in which syntax can enforce the choice of the various blocks of a transformer stack. Specifically, looking at the case of regular expressions as the simplest non-trivial example of formal language: 
			\begin{enumerate}
				\item Embeddings: what is a sensible choice of dimensionality for the embedding of a tokens which might be few in numbers but combine in very specific ways. Are the constraints of a low-dimensional embedding helpful in this context or not? Does the size of the minimal automaton recognising a regex give any information about the dimensionality of good embeddings? By extending experiments along these lines to increasingly complex types of grammars/automata we might gain some understanding of what makes a good embedding for the ask of LFLM (Large Formal Language Model)
				\item Attention mechanism: can we design constrained attention mechanisms guided by automata?
			\end{enumerate}
	
	\section{Investigating logical and compositional NN with Automata}
	Explainable AI is a very active field of research but much remains mysterious about neural networks. How can we explain their incredible effectiveness versus other models of computation? Is it possible to understand how a neural network works -- and therefore also how it doesn't -- in a structural and compositional way, that is to say by understanding it as a composition of smaller and better understood sub-systems? Since these models find applications in virtually every industry, and will more or less directly impact everyone on the planet, these are societally crucial problems. 
	
	To investigate these questions we propose to use the expertise of the Cornell pole in the theory and industrial applications of \emph{finite automata}, one of the simplest and best-understood models of computations. A finite automaton represents a simple `computing machine' which can only successfully run programs written in a simple `programming language' called a regular expression. An automaton can thus be used to solve the problem of deciding whether a program belongs to such a language or not: simply feed the program to the automaton and check whether executes successfully or not. Neural networks can also solve this classification problem, and our proposal is therefore to use finite automata as a well-understood, well-behaved and sufficiently complex benchmarking and testing suite with which to probe the inner workings of neural networks. 
	
	
	This is not a new idea, \cite{cleeremans1989finite} provides a brief but very instructive example of this line of research from a natural language processing perspective. Much of the research at the intersection between neural network and finite automata has since focused on describing the behaviour of an unknown neural network as a finite automaton \cite{weiss2018extracting,weiss2019learning} or using automata theory to describe the computational power of neural networks \cite{weiss2018practical}. Our proposed approach combines the original idea of~\cite{cleeremans1989finite} -- trying to understand how a neural network works by discovering how it internally represents the finite automaton problem it is solving -- to the more recent work of \cite{weiss2018extracting,weiss2019learning} which which gives concrete algorithms to extract this internal representation. This will allow us to perform the following type of neural network probing experiment: (a) set an automaton problem, (b) solve it with a neural network, (c) extract the network's internal representation of the automaton, and (d) compare it to the original, as described in Figure \ref{diag:strategy}. 
	
	
	Finite automata form a space of problems with a rich inner structure, for example automata $A$ and $B$ can be combined in various ways to form new automata, say $A+B$. Using the strategy of Figure~\ref{diag:strategy} we can study the compositional nature of neural networks by understanding how the internal representations of $A$ and $B$ are combined to form an internal representation of $A+B$ in the neural network. We will also investigate whether a new neural network pruning procedure developed at QMUL~\cite{pruning} in order to optimally compress neural networks, can be used to improve the Automaton Learning part of this strategy.	
	
	
	
	\begin{figure}[ht]
		\begin{center}
			\begin{tikzpicture}[node distance=9.5cm]
				\node (start) [dfa] {\large \bf (a) Automaton -- Probe};
				\node (examples) [process, above = 1cm of start] {Generates examples};
				\node (learn1) [process, right of = examples] {Learn Neural Network};
				\node (step2) [nn, below= 2.5cm of learn1] {\large \bf (b) Neural Network \\ Representation of Probe};
				\node (end) [dfa, below = 3.6cm of start] {\large \bf  (c) Automaton representation \\ of Neural Network \\ Representation of Probe};
				\node (learn2) [process, below = 2.55 of step2] {Learn Automaton};
				\node (compare) [comparison, above = 0.6cm of end] {(d) Compare};
				\draw [FARROW] (start) -- (examples);
				\draw [FARROW] (examples) -- (learn1);
				\draw [FARROW] (learn1) -- (step2);
				\draw [FARROW] (step2) -- (learn2);
				\draw [FARROW] (learn2) -- (end);
				\draw [FARROW] (end) -- (compare);
				\draw [FARROW] (start) -- (compare);
			\end{tikzpicture}
		\end{center}
		\caption{Learning and testing strategy}
		\label{diag:strategy}
	\end{figure}
	
	\bibliographystyle{plain}
	\bibliography{references}
	
\end{document}